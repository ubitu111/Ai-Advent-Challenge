# Исследование вариантов распознавания речи для Kotlin Multiplatform

## Дата исследования: Декабрь 2024

## Цель
Выбрать оптимальное решение для реализации распознавания речи (voice-to-text) в Kotlin Multiplatform приложении с поддержкой Android и Desktop (macOS).

## Рассмотренные варианты

### 1. SpeechToTextKit
**Описание:** Kotlin Multiplatform библиотека для распознавания речи с поддержкой Android и iOS.

**Преимущества:**
- Готовая библиотека для KMP
- Поддержка Android и iOS из коробки
- Reactive API с Kotlin Flows
- Интеграция с Jetpack Compose через `rememberSpeechToText()`
- Простая интеграция

**Недостатки:**
- Не поддерживает Desktop (JVM) платформы
- Требует настройки permissions на каждой платформе
- Зависит от системных API распознавания речи

**GitHub:** https://github.com/eslamwael74/SpeechToTextKit

**Вывод:** Подходит для Android/iOS, но не для Desktop.

---

### 2. Ollama Whisper API
**Описание:** Использование модели Whisper через Ollama для распознавания речи.

**Преимущества:**
- Работает локально (приватность данных)
- Поддерживает множество языков
- Высокое качество распознавания
- Уже используется в проекте (Ollama для LLM)
- Работает на всех платформах через HTTP API

**Недостатки:**
- Требует запущенный Ollama сервер
- Требует установки модели Whisper
- Может быть медленнее системных решений
- Требует отправку аудио файла на сервер

**Статус:** По состоянию на декабрь 2024, Ollama официально не поддерживает Whisper API, но есть community решения и можно использовать напрямую через OpenAI-совместимые API.

**Альтернативы:**
- **OWhisper** - локальный сервер для Whisper с поддержкой streaming
- **Speaches** - OpenAI API-совместимый сервер для транскрипции

**Вывод:** Хороший вариант, если уже используется Ollama, но требует дополнительной настройки.

---

### 3. OpenAI Whisper API (Cloud)
**Описание:** Использование облачного API OpenAI для распознавания речи.

**Преимущества:**
- Высокое качество распознавания
- Простая интеграция через HTTP API
- Поддержка множества языков
- Работает на всех платформах

**Недостатки:**
- Требует API ключ OpenAI
- Отправка данных в облако (приватность)
- Платный сервис
- Требует интернет соединение

**Вывод:** Подходит, если нет проблем с приватностью и есть бюджет.

---

### 4. Системные API (Android SpeechRecognizer / macOS Speech Framework)
**Описание:** Использование нативных API каждой платформы через expect/actual.

**Преимущества:**
- Нативная интеграция
- Хорошая производительность
- Бесплатно
- Работает офлайн (на Android)

**Недостатки:**
- Требует реализацию для каждой платформы
- Разные API на разных платформах
- На macOS Speech Framework требует macOS 10.15+
- На Android требует разрешения RECORD_AUDIO

**Вывод:** Хороший вариант для максимальной производительности, но требует больше работы.

---

### 5. Cactus Kotlin
**Описание:** Kotlin Multiplatform библиотека для on-device AI, включая Whisper.

**Преимущества:**
- On-device обработка (приватность)
- Поддержка Whisper модели
- KMP библиотека

**Недостатки:**
- Менее популярная библиотека
- Может требовать больше ресурсов устройства
- Требует загрузки модели на устройство

**Вывод:** Интересный вариант для приватности, но требует дополнительного исследования.

---

## Рекомендуемое решение

### Гибридный подход: Системные API + Ollama Whisper (fallback)

**Архитектура:**
1. **Запись голоса:** Использовать expect/actual для записи аудио на каждой платформе
   - Android: MediaRecorder
   - Desktop (macOS): AVAudioRecorder через Kotlin/Native

2. **Распознавание речи:** Два варианта
   - **Приоритет 1:** Системные API (быстро, офлайн)
     - Android: SpeechRecognizer
     - macOS: Speech Framework (если доступен)
   - **Приоритет 2:** Ollama Whisper (если системные API недоступны или для лучшего качества)
     - Использовать существующий Ollama сервер
     - Или настроить отдельный Whisper сервер

**Преимущества подхода:**
- Максимальная гибкость
- Работает на всех платформах
- Можно использовать локальные модели для приватности
- Fallback на облачные решения при необходимости

---

## Реализация

### Шаг 1: Запись аудио
Создать expect/actual интерфейс для записи:
- `expect class AudioRecorder` в commonMain
- `actual class AudioRecorder` в androidMain и desktopMain

### Шаг 2: Распознавание речи
Создать сервис распознавания:
- `SpeechRecognitionService` с поддержкой нескольких провайдеров
- Провайдер для системных API
- Провайдер для Ollama/Whisper API

### Шаг 3: Интеграция
- Добавить кнопку записи в UI
- Интегрировать с ChatViewModel
- После распознавания отправлять текст как обычное сообщение

---

## Настройка Ollama Whisper (если выбран этот вариант)

### Вариант A: Использование OpenAI-совместимого API
1. Установить Whisper сервер (например, OWhisper или Speaches)
2. Использовать через HTTP API аналогично OpenAI

### Вариант B: Прямое использование Whisper через Python
1. Установить Whisper: `pip install openai-whisper`
2. Создать простой HTTP сервер для транскрипции
3. Интегрировать в приложение

### Вариант C: Использование готового решения
- **Whisper.cpp** - C++ реализация Whisper
- **Faster-Whisper** - оптимизированная версия

---

## Итоговая рекомендация

**Для MVP:** Использовать системные API (Android SpeechRecognizer) + запись через expect/actual. Это самое быстрое решение.

**Для production:** Реализовать гибридный подход с поддержкой:
1. Системных API (приоритет)
2. Ollama/Whisper через HTTP API (fallback и для Desktop)
3. Возможность добавления других провайдеров в будущем

**Приоритет реализации:**
1. ✅ Запись аудио (expect/actual)
2. ✅ Android SpeechRecognizer
3. ⏳ Ollama Whisper API (если нужен Desktop)
4. ⏳ macOS Speech Framework (опционально)

---

## Ссылки
- [SpeechToTextKit GitHub](https://github.com/eslamwael74/SpeechToTextKit)
- [Ollama GitHub](https://github.com/ollama/ollama)
- [OpenAI Whisper](https://github.com/openai/whisper)
- [Android SpeechRecognizer](https://developer.android.com/reference/android/speech/SpeechRecognizer)
- [macOS Speech Framework](https://developer.apple.com/documentation/speech)
